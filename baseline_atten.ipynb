{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Model Define"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import moxing as mox\n","mox.file.copy_parallel(src_url=\"obs://npl-hzw/nlp/VQA_V1.0\", dst_url=\"./\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from mindspore import context\n","from easydict import EasyDict as edict\n","from mindspore import dataset as ds\n","import os\n","import mindspore.ops as ops\n","import mindspore.nn as nn\n","from mindspore.train.model import Model\n","from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# context\n","context.set_context(mode=context.PYNATIVE_MODE, save_graphs=False, device_target='CPU')\n","\n","# CONFIG\n","cfg = edict({\n","    'question_embdim': 512,\n","    'image_embdim': 512,\n","    'outdim': 1024,\n","    'hiddendim': 256,\n","    'dropout': 0.2,\n","    'answer_num': 8193,\n","    'min_lr': 0.001,\n","    'max_lr': 0.1,\n","    'epochs': 4,\n","    'batch_size': 128,\n","    'MFB_k': 2,\n","    'MFB_o': 512,\n","    'Attn_num': 16,\n","})\n","\n","decay_steps = cfg.epochs * 44416/cfg.batch_size * 0.9\n","cosine_decay_lr = nn.CosineDecayLR(cfg.min_lr, cfg.max_lr, decay_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Attention(nn.Cell):\n","    def __init__(self, config):\n","        super(Attention, self).__init__(auto_prefix=False)\n","        self.ExpandFC = nn.Dense(config.image_embdim, config.image_embdim*config.Attn_num, activation='relu')\n","        self.config = config\n","        self.norm = ops.L2Normalize(2)\n","        self.dropout = nn.Dropout(1 - config.dropout)\n","        self.unsqueeze = ops.ExpandDims()\n","        self.softmax = nn.Softmax(1)\n","        self.getWeight = nn.Dense(config.image_embdim, 1, has_bias=False)\n","\n","    def construct(self, ques_emb, img_emb):\n","        attn = self.ExpandFC(img_emb)\n","        # attn: [B, img_embdim*Attn_num]\n","        img_attn = attn.view((img_emb.shape[0], self.config.Attn_num, self.config.image_embdim))\n","        # img_attn: [B, Attn_num, img_embdim]\n","        attn = self.norm(img_attn)\n","        ques = ops.repeat_elements(self.unsqueeze(ques_emb, 1), rep = self.config.Attn_num, axis = 1)\n","        # ques: [B, Attn_num, ques_embdim]\n","        ques = self.norm(ques)\n","        attn = ques * attn\n","        attn = self.dropout(attn)\n","        attn = self.getWeight(attn)\n","        # attn: [B, Attn_num, 1]\n","        attn = self.softmax(attn)\n","        output_img = (attn * img_attn).sum(1)\n","        # output_img: [B, img_embdim]\n","        return output_img"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VQA_baseline(nn.Cell):\n","    '''\n","    config:{\n","        question_embdim 问题句嵌入dim\n","        image_embdim 图片嵌入dim\n","        outdim 输出dim\n","        dropout \n","        answer_num\n","    }\n","    '''\n","    def __init__(self, config, auto_prefix=True, flags=None):\n","        super().__init__(auto_prefix, flags)\n","        self.attn = Attention(config)\n","        self.question_dense = nn.Dense(config.question_embdim, config.outdim)\n","        self.image_dense = nn.Dense(config.image_embdim, config.outdim)\n","        self.dropout = nn.Dropout(1 - config.dropout)\n","        self.out_dense_1 = nn.Dense(config.outdim, 256)\n","        self.out_dense_2 = nn.Dense(256, config.answer_num)\n","\n","    def construct(self, ques, img):\n","        '''\n","        img:[B, image_embdim]\n","        ques:[B, question_embdim]\n","        output:[B, answer_num]\n","\n","        '''\n","        img_attn = self.attn(ques, img)\n","        ques_out = self.relu(self.question_dense(ques))\n","        img_out = self.relu(self.image_dense(img_attn))\n","        c = self.relu(self.out_dense_1(ques_out * img_out))\n","        c = self.out_dense_2(c)\n","        output = self.dropout(c)\n","        return output\n","\n","class WithLossCell(nn.Cell):\n","    def __init__(self, backbone, config):\n","        super(WithLossCell, self).__init__(auto_prefix=False)\n","        self._backbone = backbone\n","        self.loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\n","    def construct(self, ques_emb, img_emb, label):\n","        out = self._backbone(ques_emb, img_emb)\n","        loss = self.loss(out, label)\n","        return loss\n","\n","class EvalCell(nn.Cell):\n","    def __init__(self, backbone):\n","        super(EvalCell, self).__init__(auto_prefix=False)\n","        self._backbone = backbone\n","        self.onehot = ops.OneHot()\n","        self.print = ops.Print()\n","    def construct(self, ques_emb, img_emb, label):\n","        out = self._backbone(ques_emb, img_emb)\n","        return (out, label)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_dataset(batch_size, dir_path = \"./\", repeat_num = 1, is_training = True):\n","\n","    if is_training:\n","        data_dir = os.path.join(dir_path, \"trainval.mindrecord\")\n","    else:\n","        data_dir = os.path.join(dir_path, \"test.mindrecord\")\n","    data_set = ds.MindDataset(data_dir, columns_list=[\"ques_emb\",\"img_emb\", \"label\"], num_shards=1, shard_id=0)\n","    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n","    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n","    data_set = data_set.repeat(count=repeat_num)\n","    return data_set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create dataset\n","train_dataset = create_dataset(cfg.batch_size, repeat_num = 3)\n","# create model\n","vqa_baseline = VQA_baseline(cfg)\n","vqa_with_loss = WithLossCell(vqa_baseline, cfg)\n","vqa_with_acc = EvalCell(vqa_baseline)\n","opt = nn.Adam(vqa_with_loss.trainable_params(), learning_rate=cfg.learning_rate)\n","model = Model(vqa_with_loss, eval_network=vqa_with_acc, metrics={'acc'}, optimizer=opt)\n","# create callback\n","config_ck = CheckpointConfig(save_checkpoint_steps=128, keep_checkpoint_max=32)\n","ckpoint_cb = ModelCheckpoint(prefix=\"hzw\", directory=\"./checkpoint\", config=config_ck)\n","loss_cb = LossMonitor()\n","cb = [loss_cb, ckpoint_cb]\n","# start training\n","print(\"start training...\")\n","model.train(cfg.epochs, train_dataset, callbacks=cb)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eval_dataset = create_dataset(cfg.batch_size, is_training=False)\n","acc = model.eval(eval_dataset)\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"57adb5802fb0f8cfd5535bab284b845a3df436c091fabcc1c6f978836181b2be"}}},"nbformat":4,"nbformat_minor":4}
