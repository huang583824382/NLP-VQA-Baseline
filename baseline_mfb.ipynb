{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Model Define"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import moxing as mox\n","mox.file.copy_parallel(src_url=\"obs://npl-hzw/nlp/VQA_V1.0\", dst_url=\"./\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from mindspore import context, Tensor\n","from easydict import EasyDict as edict\n","from mindspore import dataset as ds\n","import os\n","import mindspore.ops as ops\n","import mindspore.nn as nn\n","from mindspore.train.model import Model\n","from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# context\n","context.set_context(mode=context.PYNATIVE_MODE, save_graphs=False, device_target='CPU')\n","\n","# CONFIG\n","cfg = edict({\n","    'question_embdim': 512,\n","    'image_embdim': 512,\n","    'outdim': 1024,\n","    'hiddendim': 256,\n","    'dropout': 0.1,\n","    'answer_num': 8193,\n","    'learning_rate': 0.005,\n","    'epochs': 4,\n","    'batch_size': 256,\n","    'MFB_k': 2,\n","    'MFB_o': 1024,\n","})\n","\n","learning_rate = []\n","warm_up = [cfg.learning_rate / math.floor(cfg.epochs / 5) * (i + 1) for _ in range(cfg.batch_size) for i in range(math.floor(cfg.epochs / 5))]\n","shrink = [cfg.learning_rate / (16 * (i + 1)) for _ in range(cfg.batch_size) for i in range(math.floor(cfg.epochs * 3 / 5))]\n","normal_run = [cfg.learning_rate for _ in range(cfg.batch_size) for i in range(cfg.epochs - math.floor(cfg.epochs / 5) - math.floor(cfg.epochs * 2 / 5))]\n","learning_rate = learning_rate + warm_up + normal_run + shrink\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MFB(nn.Cell):\n","    def __init__(self, config):\n","        super(MFB, self).__init__(auto_prefix=False)\n","        self.xFC = nn.Dense(config.question_embdim, config.MFB_k*config.MFB_o, activation='relu')\n","        self.yFC = nn.Dense(config.image_embdim, config.MFB_k*config.MFB_o, activation='relu')\n","        self.sumPooling = nn.AvgPool1d(config.MFB_k, stride=config.MFB_k)\n","        self.dropout = nn.Dropout(1 - config.dropout)\n","        self.norm = ops.L2Normalize(1)\n","        self.unsqueeze = ops.ExpandDims()\n","        self.squeeze = ops.Squeeze(1)\n","        self.relu = ops.ReLU()\n","        self.sqrt = ops.Sqrt()\n","\n","    def construct(self, ques_emb, img_emb):\n","        x_out = self.xFC(ques_emb)\n","        y_out = self.yFC(img_emb)\n","        output = self.dropout(x_out * y_out)\n","        # output: [B, MFB_k*MFB_o]\n","        output = self.squeeze(self.sumPooling(self.unsqueeze(output, 1)))\n","        output = (self.sqrt(self.relu(output)) - self.sqrt(self.relu(-output))) # 未经过测试\n","        output = self.norm(output)\n","        # output: [B, MFB_o]\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VQA_baseline(nn.Cell):\n","    '''\n","    config:{\n","        question_embdim 问题句嵌入dim\n","        image_embdim 图片嵌入dim\n","        outdim 输出dim\n","        dropout \n","        answer_num\n","    }\n","    '''\n","    def __init__(self, config, auto_prefix=True, flags=None):\n","        super().__init__(auto_prefix, flags)\n","        self.dropout = nn.Dropout(1 - config.dropout)\n","        self.FC = nn.Dense(config.MFB_o, config.answer_num, activation='relu')\n","        self.mfb = MFB(config)\n","\n","    def construct(self, ques, img):\n","        '''\n","        img:[B, image_embdim]\n","        ques:[B, question_embdim]\n","        output:[B, answer_num]\n","        '''\n","        mfb_output = self.mfb(ques, img)\n","        output = self.FC(mfb_output)\n","        output = self.dropout(output)\n","        return output\n","\n","class WithLossCell(nn.Cell):\n","    def __init__(self, backbone, config):\n","        super(WithLossCell, self).__init__(auto_prefix=False)\n","        self._backbone = backbone\n","        self.loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\n","    def construct(self, ques_emb, img_emb, label):\n","        out = self._backbone(ques_emb, img_emb)\n","        loss = self.loss(out, label)\n","        return loss\n","\n","class EvalCell(nn.Cell):\n","    def __init__(self, backbone):\n","        super(EvalCell, self).__init__(auto_prefix=False)\n","        self._backbone = backbone\n","        self.onehot = ops.OneHot()\n","        self.print = ops.Print()\n","    def construct(self, ques_emb, img_emb, label):\n","        out = self._backbone(ques_emb, img_emb)\n","        return (out, label)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_dataset(batch_size, dir_path = \"./\", repeat_num = 1, is_training = True):\n","\n","    if is_training:\n","        data_dir = os.path.join(dir_path, \"trainval.mindrecord\")\n","    else:\n","        data_dir = os.path.join(dir_path, \"test.mindrecord\")\n","    data_set = ds.MindDataset(data_dir, columns_list=[\"ques_emb\",\"img_emb\", \"label\"], num_shards=1, shard_id=0)\n","    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n","    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n","    data_set = data_set.repeat(count=repeat_num)\n","    return data_set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create dataset\n","train_dataset = create_dataset(cfg.batch_size, repeat_num = 3)\n","# create model\n","vqa_baseline = VQA_baseline(cfg)\n","vqa_with_loss = WithLossCell(vqa_baseline, cfg)\n","vqa_with_acc = EvalCell(vqa_baseline)\n","opt = nn.Adam(vqa_with_loss.trainable_params(), learning_rate=cfg.learning_rate)\n","model = Model(vqa_with_loss, eval_network=vqa_with_acc, metrics={'acc'}, optimizer=opt)\n","# create callback\n","config_ck = CheckpointConfig(save_checkpoint_steps=128, keep_checkpoint_max=32)\n","ckpoint_cb = ModelCheckpoint(prefix=\"hzw\", directory=\"./checkpoint\", config=config_ck)\n","loss_cb = LossMonitor()\n","cb = [loss_cb, ckpoint_cb]\n","# start training\n","print(\"start training...\")\n","model.train(cfg.epochs, train_dataset, callbacks=cb)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eval_dataset = create_dataset(cfg.batch_size, is_training=False)\n","acc = model.eval(eval_dataset)\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"57adb5802fb0f8cfd5535bab284b845a3df436c091fabcc1c6f978836181b2be"}}},"nbformat":4,"nbformat_minor":4}
